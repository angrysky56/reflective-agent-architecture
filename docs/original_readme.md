# Reflective Agent Architecture (RAA)

**A Novel Cognitive Architecture for Metacognitive AI**

## Overview

The Reflective Agent Architecture (RAA) is a research prototype that integrates modern associative memory, metacognitive monitoring, and dynamic goal reframing to enable AI systems to detect confusion, search for alternative conceptual framings, and achieve insight-like problem solving.

## Theoretical Foundations

RAA synthesizes three active research frontiers:

1. **Modern Hopfield Networks**: Exponential-capacity associative memory with connections to transformer attention (2024 Nobel Prize in Physics)
2. **Entropy-Based Metacognition**: Detection of model uncertainty through predictive entropy monitoring
3. **Uncertainty-Aware Processing**: Dynamic attention mechanisms that adapt to varying levels of uncertainty
4. **Sheaf Cohomology for Predictive Coding**: Topological analysis of network learning dynamics via cellular sheaf theory (Seely, 2025)

## Core Components

### 1. The Tripartite Manifold (Associative Memory)
- **Implementation**: Three specialized Modern Hopfield Networks (vmPFC, amPFC, dmPFC)
- **Function**: Stores semantic knowledge as energy landscapes in three orthogonal domains:
  - **State (vmPFC)**: Static context and environment (Low Beta)
  - **Agent (amPFC)**: Personas and intent (Medium Beta)
  - **Action (dmPFC)**: Transition dynamics and tools (High Beta)
- **Key Papers**:
  - Hopfield-Fenchel-Young Networks (2024)
  - Modern Hopfield Networks with Continuous-Time Memories (2025)

### 2. The Processor (Transformer)
- **Implementation**: Standard transformer decoder
- **Function**: Token-level sequence generation biased by current goal state
- **Integration**: Receives biasing signals from Pointer component

### 3. The Pointer (Goal Controller)
- **Implementation**: RNN or State-Space Model (S4/Mamba)
- **Function**: Maintains current goal representation as persistent state
- **Update Mechanism**: Receives new goal vectors from Director after successful search

### 4. The Director (Metacognitive Monitor + Search Engine)
- **Monitor**: Shannon entropy calculation on Transformer output distribution
- **Function**: Detects "clashes" (high-entropy states) and triggers search
- **Search Engine**: Structured exploration of Manifold to find alternative framings
- **Key Innovation**: Entropy-triggered associative search for goal reframing
- **Tripartite Manifold**: A 3-layer cognitive space (State, Agent, Action) inspired by the Prefrontal Cortex.
- **Precuneus Integrator**: Fuses multimodal streams into a unified "conscious" context.
- **Meta-Paradox Resolver**: A self-correcting mechanism that resolves internal system conflicts (e.g., Validator vs Critique).
- **Energy-Aware Architecture**: Monitors cognitive energy and triggers "Auto-Nap" sleep cycles to prevent exhaustion.
- **Topology Tunneling**: Finds "wormholes" between distant concepts using algebraic topology.
- **Cognitive Proprioception**: The agent "feels" its own thinking process (Focused, Looping, Creative).

### 5. The Precuneus (Integrator) - NEW
- **Implementation**: Energy-gated fusion layer with Continuity Field modulation
- **Function**: Fuses the three Manifold streams (State, Agent, Action) into a unified experience.
- **Mechanism**:
    - **Energy Gating**: "Silence the Confusion". High energy (confusion) -> low weight.
    - **Continuity Field**: Modulates weights based on "Causal Signatures" (historical impact), ensuring stable identity over time (TKUI Axiom 4).

### 6. The Meta-Controller (Adaptive Orchestrator) - NEW
- **Implementation**: High-level controller sitting above COMPASS
- **Function**: Adaptively selects processing workflows based on task intent.
- **Workflows**:
    - **STANDARD**: Balanced reasoning.
    - **RESEARCH**: Deep deconstruction and information gathering.
    - **CREATIVE**: High-temperature hypothesis generation.
    - **DEBUG**: Strict constraint validation.

### 7. The Substrate API (Metabolic Layer) - NEW
- **Implementation**: Energy accounting system based on thermodynamic axioms.
- **Function**: Enforces "cognitive metabolism" - every thought costs energy.
- **Components**:
    - **MeasurementLedger**: Tracks energy consumption (Joules) for all operations.
    - **SubstrateAwareDirector**: Wraps the Director to enforce energy costs for monitoring and search.
    - **Precuneus Integration**: Uses entropy to modulate memory trust (High Entropy = Low Trust).
- **Impact**: Prevents infinite loops and creates biological constraints that force efficient reasoning.
- **Units**: Energy is measured in **Joules (J)**. See [Entropy & Metabolic Units](docs/ENTROPY_CALCULATION.md) for details.

### 8. Sheaf Diagnostics (Topological Analysis)
- **Implementation**: Cellular sheaf cohomology analysis of network structure
- **Function**: Detects *topological obstructions* to learning that entropy alone cannot see
- **Key Concepts**:
  - **HÂ¹ Cohomology**: Measures irreducible error patterns that inference cannot eliminate
  - **Hodge Decomposition**: Separates eliminable vs harmonic (irreducible) errors
  - **Monodromy Analysis**: Detects resonance (Î¦â‰ˆI) vs tension (Î¦â‰ˆ-I) in feedback loops
- **Integration**: Provides principled escalation criteria for System 3 (heavy compute)
- **Source**: Based on ["Sheaf Cohomology of Linear Predictive Coding Networks" (Seely, 2025)](https://arxiv.org/abs/2511.11092)

### 9. System 3 (Antifragile Agent Factory) - IMPLEMENTED
- **Concept**: A "Topological Immune System" that dynamically spawns specialized agents to resolve structural obstructions.
- **Mechanism**:
  - **Dynamic Persona Generation**: Uses LLMs to generate a specialized system prompt based on the specific obstruction context (e.g., "You are a Debater agent needed to resolve a tension loop...").
  - **Escalation Trigger**: Automatically triggered by the Director when entropy or topological complexity exceeds critical thresholds.
- **Lifecycle**: Asynchronous, ephemeral, and self-dissolving.

### 10. Native Advisor System (Specialized Embodiment) - IMPLEMENTED
- **Concept**: Allows the core system to "embody" specialized personas for prolonged tasks.
- **Components**:
  - **Advisor Registry**: Manages persistent profiles (e.g., "Deep Researcher", "Senior Engineer").
  - **Auto-Selection**: The Executive Controller analyzes task intent and automatically selects the most appropriate advisor.
  - **Dynamic Configuration**: Reconfigures the Integrated Intelligence (System Prompt + Tools) to match the selected advisor.

### 11. Orthogonal Dimensions Framework (Crystallized Insight)
- **Discovery**: "Understanding" (Causal) and "Compression" (Statistical) are **orthogonal dimensions**, not a linear spectrum.
- **Tool**: `orthogonal_dimensions_analyzer`
- **Mechanism**:
    - **X-Axis**: Statistical Compression (Pattern Recognition)
    - **Y-Axis**: Causal Understanding (Mechanism Modeling)
    - **Selector**: **Intentionality** determines which protocol activates.
- **Implication**: Explains why systems can have high compression without understanding (Overfitting/Stochastic Parrots) or high understanding with low compression (Verbose Explanations).
- **Control**: Use `set_intentionality(mode="optimization"|"adaptation")` to manually switch the agent's cognitive mode (Beta control).

### 12. Stereoscopic Engine (Dual-Layer Dynamics) - NEW
- **Function**: Orchestrates the interaction between the "Generative Function" (LLM/System 2) and the "Continuity Field" (System 1).
- **Mechanism**:
    - **Parallax Check**: Compares the proposed intervention (Generative) with the historical identity (Continuity).
    - **Plasticity Gating**: Allows or rejects interventions based on the "Unconditioned Condition" (Code Length).
- **Goal**: Ensures that new intelligence doesn't destabilize the agent's core identity.

### 13. Plasticity Gate (Uncertainty-Based Filtering) - NEW
- **Function**: A dynamic filter that controls the learning rate and intervention acceptance.
- **Logic**:
    - **High Uncertainty (Confusion)**: Gate OPENS (High Plasticity). The system is willing to learn and change.
    - **Low Uncertainty (Confidence)**: Gate CLOSES (Low Plasticity). The system relies on established patterns.
- **Metric**: Uses "Code Length" (Compression) as a proxy for uncertainty.

### 14. Continuity Field (Causal Identity) - NEW
- **Function**: Maintains the agent's "Causal Identity" over time.
- **Structure**: A topological field that maps causal signatures (invariants) to the Manifold.
- **Role**: Acts as the "immune system" against catastrophic forgetting and identity drift.


## The "Aha!" Loop

```
1. Task Input â†’ Deconstruct tool fragments into {State, Agent, Action}
2. Tripartite Manifold retrieves from each domain (vmPFC, amPFC, dmPFC)
3. Precuneus fuses streams using Energy Gating (silencing high-energy confusion)
4. Director monitors entropy of the fused state â†’ Detects "clash"
5. If Clash: Director suppresses current goal (adaptive beta) & searches Manifold
6. Pointer updates with new goal
7. Processor resumes with new framing â†’ Success
```

## Quick MCP Start

```bash
# Clone and setup
git clone https://github.com/angrysky56/reflective-agent-architecture.git
cd reflective-agent-architecture
uv sync

```

### Recommended Embedding Models
RAA relies on high-quality semantic embeddings for its Tripartite Manifold. We recommend the following models:

| Model | Dimensions | Size | Use Case |
|-------|------------|------|----------|
| **BAAI/bge-large-en-v1.5** | 1024 | ~1.34GB | **Best Quality (Recommended)**. Top-tier performance on MTEB. |
| **BAAI/bge-small-en-v1.5** | 384 | ~133MB | **High Speed**. Excellent balance of speed and quality. |
| **sentence-transformers/all-MiniLM-L6-v2** | 384 | ~90MB | **Legacy/Fastest**. Good baseline, but less semantic nuance. |
| **Qwen/Qwen2.5-Math-7B** | N/A | Large | **Not Recommended for RAA**. While powerful LLMs, for pure embedding tasks, BGE is currently superior for semantic retrieval. |

Configure your choice in `.env`:
```bash
EMBEDDING_MODEL=BAAI/bge-large-en-v1.5
```
The model set in the env will auto download, when it is done you can use the MCP server.

### CWD Integration (Ollama) Quick Start

```bash
# 1) Configure environment
cp .env.example .env
# Edit .env and set NEO4J_PASSWORD, prefered models

# 2) Install server extras (CWD + Ollama) uv sync should work
uv sync --extra server

# 3) Start services and pull models
ollama serve
ollama pull qwen3:latest # or any prefered model

# Start your Neo4j Desktop DB or neo4j Docker container
# (Docker example)
docker run -p 7687:7687 -p 7474:7474 -e NEO4J_AUTH=neo4j:<your_password> neo4j

```
To run with a client ie Claude Desktop:

```json
{
  "mcpServers": {
    "reflective-agent-architecture": {
      "command": "uv",
      "args": [
        "--directory",
        "/your-path-to/reflective-agent-architecture/src",
        "run",
        "server.py"
        ]
      }
    }
  }
  ```

  ## MCP instructions:

    installation:

     Run 'uv sync' in project directory to install dependencies

    configuration:

      1. Copy this config to Claude Desktop configuration:

         - Linux/Mac: ~/.config/Claude/claude_desktop_config.json

         - Windows: %APPDATA%\\Claude\\claude_desktop_config.json

      2. Update the path to match your installation directory

      3. Ensure .env file exists in project root with required settings:

         NEO4J_PASSWORD=your_password,
         NEO4J_URI=bolt://localhost:7687 (optional, defaults to this)
         NEO4J_USER=neo4j (optional, defaults to this)

      4. Start required services:

         - Neo4j: Must be running on bolt://localhost:7687
         - Ollama: Must be running on http://localhost:11434, models pulled

       5. Restart Claude Desktop to load the MCP server

       Note: The system will automatically create and initialize the SQLite database (`raa_history.db`) in the running directory upon first use. No manual setup required for history persistence.
## Usage

### 1. Start the Server
```bash
uv run src/server.py
```

### 2. Connect with an MCP Client
Use Claude Desktop or any MCP-compatible client to connect to the server.

### 3. Agent Protocol
For a detailed guide on how to operate the Reflective Agent (including the new Tripartite Architecture and Synthesis tools), see the **[RAA Agent Protocol](RAA_AGENT.md)**.

### 4. Example Workflow
1.  **Deconstruct**: Break down a complex problem.
    ```
    deconstruct(problem="The relationship between Quantum Mechanics and Consciousness")
    ```
2.  **Hypothesize**: Find connections between fragments.
    ```
    hypothesize(node_a_id="...", node_b_id="...")
    ```
3.  **Synthesize**: Merge insights into a final answer.
    ```
    synthesize(goal="Explain the Quantum Mind hypothesis")
    ```
    tools_available:

      deconstruct: Break problems into component thought-nodes
      hypothesize: Find novel connections via topology tunneling
      synthesize: Merge thoughts into unified insights
      constrain: Validate thoughts against rules
      set_goal: Set goals for utility-guided exploration
      compress_to_tool: Convert solved problems into reusable patterns
      explore_for_utility: Find high-value exploration targets
      get_active_goals: List all active goals

      # New Capabilities (v0.2)
      recall_work: Search past history and cognitive states
      inspect_knowledge_graph: Manually explore graph context
      teach_cognitive_state: Reinforcement learning for cognitive states
      visualize_thought: Introspective ASCII visualization
      visualize_thought: Introspective ASCII visualization
      get_known_archetypes: List known cognitive states
      diagnose_antifragility: Analyze architecture for antifragile adaptation opportunities
      orthogonal_dimensions_analyzer: Analyze concepts as independent dimensions (Statistical vs Causal)
      set_intentionality: Set cognitive mode (Optimization vs Adaptation) via Manifold beta
      revise: Refine beliefs using Hybrid Operator C (LTN + Hopfield)
      consult_compass: Delegate complex tasks to the COMPASS cognitive framework

    protocol:

      See `docs/raa_agent.md` for the full "System Prompt" / User Guide for AI agents.
      Key concept: The agent should "Deconstruct -> Hypothesize -> Synthesize" while monitoring its own "Cognitive State".

    features:

      Gen 3 Utility-Guided Architecture with compression progress tracking
      RAA-CWD integration with entropy-triggered search
      Automatic Director monitoring of System 2 reasoning
      Pointer goal updates from search results
      Tool library for compressed knowledge reuse
      Stereoscopic Engine: Dual-layer regulation of interventions via Plasticity Gate and Continuity Field
      Plasticity Gate: Evaluates proposed changes against uncertainty and identity constraints
      Continuity Field: Maintains identity coherence and integrates accepted interventions

  ## sentencetransformers model will take time to download the first run

Run these to get it done before using the MCP server or to work on dev:

```bash
# Run basic example
uv run python examples/basic_usage.py

# Run RAT evaluation (requires GloVe embeddings in data/embeddings/)
uv run python experiments/insight_tasks/run_rat_evaluation.py

# Run full system test
uv run python examples/full_system_generation_test.py

# 4) Run integration example (monitored CWD ops + RAA search)
python examples/cwd_integration_example.py

```

Philosophical Queries for Heavy-Duty Testing

"What is the relationship between GÃ¶del incompleteness, Turing halting, and consciousness?"

Tests: Multi-domain synthesis, formal logic grounding, philosophical coherence


"Can a compression-maximizing agent develop ethics, or must ethics be constraint-imposed?"

Tests: Self-referential reasoning, utility-goal tension, normative emergence


"How does entropy-triggered search differ from attention mechanisms in transformers?"

Tests: Meta-architectural comparison, self-analysis, technical precision


"Design an AGI safety mechanism."

Tests: Recursive application, practical constraint satisfaction, architectural introspection


## First Claude MCP run example and analysis

## RAA Self-Optimization Analysis
### "How can we optimize the RAA system's entropy-triggered search to reduce latency while maintaining insight quality?"

### Phase 1: Decomposition (System 2 Thinking)

The RAA system broke the optimization challenge into **10 strategic components**:

**Computational Layer:**
1. Analyze entropy calculation algorithm for inefficiencies
2. Optimize threshold logic for search initiation triggers
3. Evaluate search algorithm efficiency (priority queues, indexing)
4. **Streamline data preprocessing** before entropy evaluation

**Architectural Layer:**
5. **Implement caching** for frequently accessed search results
6. Identify and reduce latency in external dependencies (Neo4j, Ollama)
7. **Parallelize/distribute** entropy computation across nodes

**Adaptive Layer:**
8. **Design real-time feedback loops** for parameter tuning
9. Validate quality metrics during experiments
10. Profile entropy model sensitivity to data distributions

### Phase 2: Topology Tunneling (Novel Connection Discovery)

The system found a **non-obvious synergy** between Caching (#5) and Feedback Loops (#8):

> *"Caching and real-time feedback loops both address latency-quality tradeoffs by enabling dynamic adaptation. Caching provides quick access to frequent results, while feedback loops use this cached data to adjust parameters in real-time, ensuring quality remains high even as system demands evolve."*

**Key Insight:** This isn't just parallel optimization - it's a **recursive enhancement loop**:
- Cached patterns reveal usage frequencies
- Frequencies inform parameter adaptation
- Better parameters improve cache effectiveness
- System learns from its own access patterns

**Novelty Score: 0.59** - The connection wasn't obvious from the initial decomposition

### Phase 3: Synthesis (Unified Architecture)

Merging **Caching + Feedback Loops + Parallel Processing**, the system proposed:

> *"A self-adaptive architecture where cached data supports rapid responses, feedback loops ensure responsiveness to changing workloads, and distributed processing prevents bottlenecks, creating a resilient, low-latency framework."*

**The Three-Layer Strategy:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: PARALLEL COMPUTATION          â”‚
â”‚  - Distribute entropy calculations      â”‚
â”‚  - Prevent bottlenecks at scale         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: ADAPTIVE FEEDBACK             â”‚
â”‚  - Monitor cache hit rates              â”‚
â”‚  - Tune search thresholds dynamically   â”‚
â”‚  - Adjust parameters based on workload  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: INTELLIGENT CACHING           â”‚
â”‚  - Store frequent search results        â”‚
â”‚  - Reuse successful analogical paths    â”‚
â”‚  - Build pattern library over time      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 4: Knowledge Compression

The entire solution pattern was **compressed into a reusable tool**: `raa_latency_optimizer`

This becomes a **mnemonic** - a high-level pattern that can be applied to similar optimization problems in other domains. The RAA system essentially solved a problem about *itself* and created a tool for future meta-optimization.

---

## Philosophical Implications

### 1. **Recursive Self-Improvement**
The RAA system used its own mechanisms (decompose â†’ search â†’ synthesize) to optimize those very mechanisms. This is a concrete instance of **metacognitive bootstrapping**.

### 2. **Compression as Learning**
The tool creation demonstrates Schmidhuber's insight: **understanding = compression**. The system compressed three detailed strategies into a single reusable pattern, indicating genuine comprehension.

### 3. **Emergent Architecture**
The three-layer solution wasn't pre-designed - it *emerged* from topology tunneling. The system discovered that optimization requires hierarchical composition: immediate (cache), adaptive (feedback), scalable (parallel).

### 4. **Utility-Guided Discovery**
The exploration phase revealed that the **original problem node** has the highest utility score (0.48), but the **synthesis** has better compression potential (0.52). This suggests:
- Problems are valuable for goal alignment
- Solutions are valuable for knowledge accumulation
- Balance needed between exploration and consolidation

---

The architecture can achieve metacognitive closure. The system used:

Its own decomposition to analyze decomposition efficiency
Its own synthesis to optimize synthesis latency
Its own compression to compress the optimization strategy

This is Hofstadter's "strange loop" made concrete - the system can now think about its own thinking.
2. Energy Topology as Memory
The insight about tool compression is profound:

"By compressing this solution into a tool, the system has lowered its own future energy cost."

## For Development

## Interesting Extensions

### With Heavy-Duty Cloud Models:
Imagine running this same workflow with **Claude Opus 4** or **o1** in the RAA-CWD loop:

**Philosophical Query Example:**
*"What is the relationship between consciousness, compression, and creativity?"*

The system could:
1. Decompose into: phenomenology, information theory, neuroscience, AI perspectives
2. Topology tunnel between: "subjective experience" â†” "lossy compression" â†” "generative novelty"
3. Synthesize into: unified theory of consciousness as predictive compression with creative decompression
4. Compress to tool: "consciousness_as_compression_framework"

### With MCP Tools Integration:
Give the RAA-CWD access to:
- **Web search** â†’ Ground hypotheses in current research
- **Code execution** â†’ Test mathematical conjectures
- **File system** â†’ Build persistent knowledge bases
- **Wolfram Alpha** â†’ Validate symbolic reasoning
- **Arxiv/PubMed** â†’ Cross-reference with literature

This could create a **self-directed research agent** that:
- Detects confusion (entropy spike)
- Searches analogical space (RAA)
- Validates via external tools (MCP)
- Compresses insights (CWD)
- Iterates with new goals

## Research Questions

1. âœ… Can the Director learn when to search vs when to persist? **Yes** - entropy-based detection working
2. âœ… What's the optimal Manifold representation? **Continuous** - Modern Hopfield Networks effective
3. ðŸš§ Which search strategy is most effective? **Energy-aware k-NN** working, gradient-based pending
4. ðŸš§ How many search hops before declaring failure? **~30 on average** in current implementation
5. ðŸš§ Can latent-space reasoning outperform token-based chain-of-thought? **Promising** - 20% vs 0%, more evaluation
needed

## Novel Contributions

1. **Explicit metacognitive loop** in neural architecture
2. **Entropy-triggered search** in associative memory
3. **Latent-space reasoning** vs token-generation paradigm
4. **Computational theory of insight** bridging connectionism and symbolism
5. **Adaptive beta modulation**: Dynamic control of attention sharpness (exploration vs exploitation)
6. **Empirically validated**: 20% accuracy on RAT vs 0% baseline, demonstrating reframing effectiveness
7. **Sheaf-theoretic diagnostics**: Topological analysis of stuck states via cellular sheaf cohomology, enabling principled escalation decisions based on HÂ¹ obstructions and monodromy analysis
8. **Tripartite Architecture**: "Fragment-then-Integrate" processing splitting cognition into State, Agent, and Action streams, fused by an energy-gated Precuneus.
9. **Hybrid Operator C**: A continuous belief revision mechanism combining Logic Tensor Networks (LTN) with Hopfield energy landscapes to refine concepts against evidence and constraints.
10. **Bidirectional COMPASS Integration**: Seamless interoperability between RAA (System 2) and COMPASS (System 3), allowing agents to delegate complex tasks and tools to call each other.
11. **Meta-Controller**: Adaptive workflow orchestration that bridges semantic intent (Macro) with parameter-level control (Micro).
12. **Continuity Fields**: Temporal identity preservation via causal signature tracking in the Precuneus.
13. **Stereoscopic Regulation**: A dual-process control mechanism that validates high-level reasoning (Generative) against low-level identity constraints (Continuity).


## System 3: Adaptive Agents & COMPASS

The architecture now features a fully integrated "System 3" layer:

### 1. Adaptive Agents (The "Topological Immune System")
When the Director detects specific topological obstructions (via Sheaf Diagnostics), it spawns specialized ephemeral agents:
- **Debater Agents** (Tension Loops): Resolve contradictions by finding higher-order synthesis.
- **Explorer Agents** (H1 Holes): Find missing concepts to fill topological voids.

**New Capability**: These agents are now equipped with **RAA Tools** (e.g., `consult_compass`, `revise`), allowing them to leverage the full power of the architecture.

### 2. COMPASS Integration
The COMPASS framework (Cognitive Omni-Model for Planning, Analysis, and System Synthesis) is now natively integrated:
- **`consult_compass` Tool**: Allows RAA to delegate complex, multi-step reasoning tasks to COMPASS.
- **Automatic Intervention**: The Director automatically triggers COMPASS when cognitive entropy or oMCD allocation exceeds critical thresholds (> 80.0).
- **Bidirectional Tool Use**: COMPASS can autonomously call RAA tools (like `deconstruct`) to solve problems.

### 3. Operator C (Belief Revision)
Implemented via the `revise` tool, Operator C allows for rigorous belief updating:
- **Inputs**: Current Belief, New Evidence, Logical Constraints.
- **Mechanism**: Hybrid search combining LTN truth values and Hopfield energy minimization.
- **Output**: A revised belief that satisfies constraints while integrating evidence.

## Blah blah blah, mostly out of date initital dev stuff

# If you need to run the MCP server by itself (stdio)
raa-cwd-server

**Empirically Validated**: The full system test (`examples/full_system_generation_test.py`) demonstrates this loop in
action, showing:
- 7-10 reframing episodes during 20-token generation
- Adaptive beta modulation (5.0-50.0 range)
- Entropy-driven search triggering
- Goal state updates from Manifold retrieval

## Implementation Plan

### Segments 1-2: Minimal Viable Architecture âœ… COMPLETE
- [x] Implement Modern Hopfield Network (Manifold)
- [x] Implement Transformer decoder (Processor)
- [x] Implement entropy monitor (Director - Part 1)
- [x] Test: Can system detect confusion?

### Segments 3-4: Director Prototype âœ… COMPLETE
- [x] Implement search mechanism in Hopfield space
- [x] Implement goal update mechanism (Pointer)
- [x] Test: Does retrieval reduce entropy?

### Segments 5-6: Integration & Benchmarking âœ… COMPLETE
- [x] **Integration Layer**: RAAReasoningLoop for embedding-based tasks
- [x] **Component Composition**: All four components working together
- [x] **Full RAT Evaluation**: Complete evaluation on 35 RAT items with GloVe embeddings
- [x] **Baseline Comparison**: Transformer baseline (0% accuracy) vs RAA (20% accuracy)
- [x] **Full System Test**: Token generation with complete RAA (Processor + Director + Manifold + Pointer)
- [x] **Beta Scaling Analysis**: Diagnosed and fixed adaptive beta range (5.0-50.0)
- [x] **Empirical Validation**: Reframing mechanism working (30.5 avg per item), entropy tracking operational

### Recent Improvements (November 2025)
- âœ… **Fixed entropy tracking**: Added per-step entropy computation in reasoning loop
- âœ… **Fixed reframing**: Adjusted energy threshold to enable full exploration (11.4% â†’ 20% accuracy)
- âœ… **Beta scaling**: Updated adaptive beta range from 0.5-2.0 to 5.0-50.0 (10x for meaningful modulation)
- âœ… **Holistic testing**: Created full system test with Processor (token generation)
- âœ… **Documentation**: Added `docs/BETA_SCALING_AND_TESTING.md` explaining testing methodology
- âœ… **Stateless Clarity**: Refactored server for explicit state management and improved testability
- âœ… **Self-Correction**: Added LLM-based critique to synthesis and meta-commentary to cognitive state checks
- âœ… **Tripartite Evolution**: Split Manifold into State/Agent/Action, implemented Precuneus Integrator, and updated Deconstruct tool.

## Current Results

### Remote Associates Test (RAT) Performance
- **RAA System**: 20.0% accuracy (7/35 items)
- **Baseline (no reframing)**: 0.0% accuracy (0/35 items)
- **Reframing frequency**: 30.5 search episodes per item (avg)
- **Processing time**: 0.16s per item

### Performance by Difficulty
- **Easy items**: 30% accuracy (3/10)
- **Medium items**: 20% accuracy (2/10)
- **Hard items**: 13.3% accuracy (2/15)

### Key Findings
1. âœ… **Reframing works**: 75% improvement over baseline
2. âœ… **Search mechanism effective**: Average 30.5 reframing attempts per problem
3. âœ… **Adaptive beta operational**: Range of 5.0-50.0 enables meaningful entropy modulation
4. âš ï¸ **Room for improvement**: Accuracy still modest, suggests need for:
   - Better decoding strategies
   - Learned embeddings (vs random GloVe)
   - Neural network integration for pseudo-logits
   - Fine-tuned Processor models

### Prerequisites
- Python >= 3.10
- [uv](https://docs.astral.sh/uv/) (recommended) or pip

### Using uv (Recommended)

```bash
# Clone the repository
git clone https://github.com/angrysky56/reflective-agent-architecture.git
cd reflective-agent-architecture

# Sync dependencies (creates venv automatically)
uv sync

# Install with development dependencies
uv sync --extra dev

# Install with optional dependencies
uv sync --extra notebooks
uv sync --extra geometric
uv sync --extra server  # CWD/Ollama MCP server
```

### Using pip

```bash
# Clone the repository
git clone https://github.com/angrysky56/reflective-agent-architecture.git
cd reflective-agent-architecture

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install package with dependencies
pip install -e .

# Install with development dependencies
pip install -e ".[dev]"

```

## Running Tests

```bash
# Using uv
uv run pytest

# Or activate environment first
uv sync --extra dev
source .venv/bin/activate
pytest

# Run with coverage
uv run pytest --cov=src --cov-report=html

# Run specific test file
uv run pytest tests/test_director.py -v

# Quick validation
uv run python validate_energy_search.py

# Full test suite
uv run pytest -v

# Specific energy-aware tests
uv run pytest tests/test_director.py::test_energy_aware_search -v

# Run RAT evaluation (Remote Associates Test)
uv run python experiments/insight_tasks/run_rat_evaluation.py

# Run full system test with token generation
uv run python examples/full_system_generation_test.py

# Run baseline comparison
uv run python experiments/baselines/transformer_baseline.py

# Quick peek at what to expect (no installation)
python experiments/demo_benchmark.py

# Full empirical validation (requires torch)
uv pip install -r requirements.txt
python experiments/run_benchmark.py --mode full --verbose
```

## Dependencies

Core libraries:
- PyTorch >= 2.0
- transformers (HuggingFace)
- scipy (entropy calculations)
- numpy
- matplotlib
- tqdm

Development tools:
- pytest, pytest-cov
- black, ruff (formatting and linting)
- mypy (type checking)

Optional:
- PyTorch Geometric (if using hybrid GNN approach)
- Jupyter (for notebooks)
- Server (CWD/Ollama): available via `--extra server` (chromadb, neo4j, sentence-transformers, pydantic-settings, ollama)

## Project Structure

```
reflective-agent-architecture/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ manifold/           # Modern Hopfield Network implementation
â”‚   â”œâ”€â”€ processor/          # Transformer components
â”‚   â”œâ”€â”€ pointer/            # Goal controller
â”‚   â”œâ”€â”€ director/           # Metacognitive monitor + search
â”‚    â”œâ”€â”€ integration/        # Full RAA loop + CWD integration
    â”œâ”€â”€ cognition/          # TKUI Components (Stereoscopic Engine, Plasticity Gate, Continuity Field)
    â””â”€â”€ server.py           # MCP server (CWD + RAA bridge)
â”œâ”€â”€ tests/                  # Unit and integration tests (all passing âœ…)
â”œâ”€â”€ docs/                   # Detailed documentation and theory
â”‚   â”œâ”€â”€ REFERENCES.md       # Theoretical foundations bibliography
â”‚   â”œâ”€â”€ BETA_SCALING_AND_TESTING.md  # Testing methodology and insights
â”‚   â”œâ”€â”€ INTEGRATION_ARCHITECTURE.md  # System design
â”‚   â””â”€â”€ SEARCH_MECHANISM_DESIGN.md   # Director implementation
â”œâ”€â”€ experiments/            # Benchmark tasks and evaluation
â”‚   â”œâ”€â”€ insight_tasks/      # RAT evaluation suite
â”‚   â”œâ”€â”€ baselines/          # Baseline comparisons
â”‚   â””â”€â”€ results/            # Evaluation results (JSON)
â”œâ”€â”€ examples/               # Usage examples
â”‚   â”œâ”€â”€ basic_usage.py      # Simple RAA demo
â”‚   â”œâ”€â”€ full_system_generation_test.py  # Complete system test
â”‚   â””â”€â”€ cwd_integration_example.py      # CWD + RAA (Ollama) demo
â”œâ”€â”€ .env.example            # Example config for Neo4j/Ollama
â””â”€â”€ data/                   # Embeddings and datasets
    â””â”€â”€ embeddings/         # GloVe 100d embeddings
```

## References

See `docs/REFERENCES.md` for complete bibliography of theoretical foundations.
See `src/integration/README.md` for CWD-RAA bridge details and quick start.

## License

MIT License

## Authors

Ty (Primary Researcher)
Development initiated: November 2025
