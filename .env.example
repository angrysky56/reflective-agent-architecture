# CWD-RAA Integration Configuration
# Copy this to .env and set your values

# Neo4j Configuration (required for CWD)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_password_here

# LLM Provider Configuration
# Options: ollama, openai, anthropic, gemini, huggingface, lm_studio
LLM_PROVIDER=ollama

# Ollama Configuration
LLM_BASE_URL=http://localhost:11434
LLM_MODEL=kimi-k2-thinking:cloud

# OpenAI / LM Studio Configuration
# OPENAI_API_KEY=sk-...
# OPENAI_BASE_URL=http://localhost:1234/v1  # For LM Studio

# Anthropic Configuration
# ANTHROPIC_API_KEY=sk-ant-...

# Google Gemini Configuration
# GEMINI_API_KEY=...

# Hugging Face Configuration
# HF_TOKEN=hf_...

# COMPASS Model (can be different from RAA's LLM_MODEL)
COMPASS_MODEL=kimi-k2-thinking:cloud

# COMPASS Tool Configuration.
# Potentially unsafe if working, be carefull
COMPASS_TOOLS_ENABLED=True


# Embedding Model (sentence-transformers)
# Recommended: BAAI/bge-large-en-v1.5 (1024-dim, Best Quality)
# Alternative: BAAI/bge-small-en-v1.5 (384-dim, High Speed)
EMBEDDING_MODEL=BAAI/bge-large-en-v1.5

# ChromaDB Configuration
CHROMA_PATH=./chroma_data

# RAA Configuration
CONFIDENCE_THRESHOLD=0.5
